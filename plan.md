# AgentSwarm â€” Project Plan

## Vision

Build a massively parallel autonomous coding system for a hackathon. A local orchestrator (running on your machine) fans out tasks to ~100 concurrent Modal sandboxed coding agents, all committing to the same repo, producing a non-trivial software project autonomously at ~1,000 commits/hour.

The hackathon deliverable is both **the harness itself** and **whatever it builds** (VoxelCraft â€” a browser-based Minecraft clone in TypeScript + raw WebGL2).

---

## Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  YOUR MACHINE (Local)                                       â”‚
â”‚                                                             â”‚
â”‚  main.ts â”€â”€â”€ Orchestrator                                   â”‚
â”‚    â”œâ”€â”€ Planner     (streaming LLM loop: Task[] â†’ dispatch)  â”‚
â”‚    â”œâ”€â”€ Subplanner  (recursive decomposition of big tasks)   â”‚
â”‚    â”œâ”€â”€ WorkerPool  (spawns Modal sandboxes via Python)       â”‚
â”‚    â”œâ”€â”€ TaskQueue   (priority queue + state machine)          â”‚
â”‚    â”œâ”€â”€ MergeQueue  (background: fetch â†’ merge â†’ main)       â”‚
â”‚    â”œâ”€â”€ GitMutex    (serializes local git operations)         â”‚
â”‚    â”œâ”€â”€ Monitor     (health checks, stuck detection, metrics) â”‚
â”‚    â””â”€â”€ Reconciler  (periodic tsc + npm test â†’ fix tasks)    â”‚
â”‚                                                             â”‚
â”‚  target-repo/      (the project being built)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚  spawn_sandbox.py (Python subprocess)
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MODAL (Remote â€” Ephemeral Sandboxes)                       â”‚
â”‚                                                             â”‚
â”‚  Each sandbox:                                              â”‚
â”‚    1. Receives task.json (written to /workspace)            â”‚
â”‚    2. Clones target repo (token-authed), checks out branch  â”‚
â”‚    3. Runs worker-runner.js (Pi coding agent SDK)           â”‚
â”‚    4. Agent calls LLM, writes code, commits                 â”‚
â”‚    5. Pushes branch to GitHub                               â”‚
â”‚    6. Writes result.json (Handoff)                          â”‚
â”‚    7. Sandbox terminates                                    â”‚
â”‚                                                             â”‚
â”‚  LLM Backend: GLM-5 on Modal 8x B200 via SGLang            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Protocol: How a Task Flows (Streaming Model)

```
1. PLANNER reads repo state + FEATURES.json
   â†“
2. PLANNER calls LLM â†’ creates 50-100 Task[] â†’ dispatches immediately
   â†“
3. Tasks dispatch concurrently (up to maxWorkers=100)
   Each task: WorkerPool â†’ spawn_sandbox.py â†’ Modal sandbox
   â†“
4. SANDBOX AGENT (Pi SDK) receives task
   â†’ Reads relevant files in scope
   â†’ Calls LLM (GLM-5 via Modal)
   â†’ Writes code, commits to branch
   â†’ Pushes branch to GitHub
   â†’ Writes result.json (Handoff)
   â†“
5. ORCHESTRATOR reads result.json, terminates sandbox
   â†’ Handoff pushed to pendingHandoffs queue
   â†“
6. MERGE-QUEUE (background) fetches branch, merges to main
   â†’ GitMutex serializes all local git operations
   â†’ If conflict: skip + log
   â†“
7. PLANNER collects completed handoffs continuously
   â†’ After 3+ handoffs arrive, triggers re-planning
   â†’ Emits new tasks while old ones still running
   â†“
   (loop continues until FEATURES.json is complete or max iterations)
```

---

## Budget

| Resource | Credits | Burn Rate | Notes |
|----------|---------|-----------|-------|
| Modal | $5,000 | Sandboxes: ~$0.02-0.05/task. GLM-5 8xB200: ~$50/hr | Sandboxes are cheap. Self-hosted LLM scales to zero when idle. |
| RunPod | $600 | H200 SXM 8x: ~$28.72/hr | Currently down. Modal is primary. |

### GLM-5 Deployment Status

| Provider | GPU | $/hr (8x) | Status |
|----------|-----|-----------|--------|
| Modal | 8x B200 | ~$50/hr | âœ… LIVE â€” `https://cameronai--glm5-inference-glm5.us-east.modal.direct` |
| RunPod | 8x H200 SXM | ~$28.72/hr | âŒ DOWN â€” endpoint unavailable |

**Strategy**: Modal-only for now. RunPod as backup when it comes back online.

---

## Repository Structure

```
agentswarm/
â”œâ”€â”€ dashboard.py                  # Rich terminal dashboard (748 lines, fullscreen TUI)
â”œâ”€â”€ package.json                  # Root monorepo (pnpm + turborepo)
â”œâ”€â”€ tsconfig.base.json
â”œâ”€â”€ turbo.json
â”œâ”€â”€ pnpm-workspace.yaml
â”œâ”€â”€ .env                          # LLM_ENDPOINTS, GIT_REPO_URL, GIT_TOKEN
â”‚
â”œâ”€â”€ .pi/
â”‚   â””â”€â”€ extensions/
â”‚       â””â”€â”€ swarm.ts              # Pi extension: launch_swarm, swarm_status, swarm_stop (436 lines)
â”‚
â”œâ”€â”€ packages/
â”‚   â”œâ”€â”€ core/                     # Shared types, protocol, logger, git ops
â”‚   â”‚   â””â”€â”€ src/
â”‚   â”‚       â”œâ”€â”€ types.ts          # Task, Handoff, HarnessConfig, MetricsSnapshot
â”‚   â”‚       â”œâ”€â”€ protocol.ts       # TaskAssignment, TaskResult, ProgressUpdate
â”‚   â”‚       â”œâ”€â”€ git.ts            # 10 async git functions + 4 types
â”‚   â”‚       â”œâ”€â”€ logger.ts         # Structured JSON logger
â”‚   â”‚       â””â”€â”€ index.ts          # Barrel export
â”‚   â”‚
â”‚   â”œâ”€â”€ orchestrator/             # LOCAL â€” runs on your machine
â”‚   â”‚   â””â”€â”€ src/
â”‚   â”‚       â”œâ”€â”€ main.ts           # Entry point â€” creates orchestrator, signal handling
â”‚   â”‚       â”œâ”€â”€ orchestrator.ts   # Factory: wires config, components, callbacks
â”‚   â”‚       â”œâ”€â”€ config.ts         # OrchestratorConfig from env vars
â”‚   â”‚       â”œâ”€â”€ planner.ts        # Streaming planner: dispatch â†’ collect â†’ replan
â”‚   â”‚       â”œâ”€â”€ subplanner.ts     # Recursive subplanner for large tasks
â”‚   â”‚       â”œâ”€â”€ shared.ts         # readRepoState, parseLLMTaskArray, ConcurrencyLimiter, GitMutex
â”‚   â”‚       â”œâ”€â”€ worker-pool.ts    # Spawns ephemeral Modal sandboxes via Python subprocess
â”‚   â”‚       â”œâ”€â”€ task-queue.ts     # Priority queue + state machine
â”‚   â”‚       â”œâ”€â”€ merge-queue.ts    # Background merge queue with GitMutex + fetch-from-origin
â”‚   â”‚       â”œâ”€â”€ reconciler.ts     # Periodic tsc + npm test â†’ LLM â†’ fix tasks
â”‚   â”‚       â”œâ”€â”€ monitor.ts        # Health checks, stuck detection, metrics
â”‚   â”‚       â”œâ”€â”€ llm-client.ts     # Multi-endpoint LLM client with weighted routing
â”‚   â”‚       â””â”€â”€ index.ts          # Barrel export
â”‚   â”‚
â”‚   â”œâ”€â”€ sandbox/                  # REMOTE â€” runs inside Modal sandboxes
â”‚   â”‚   â””â”€â”€ src/
â”‚   â”‚       â”œâ”€â”€ worker-runner.ts  # Pi SDK agent: task â†’ code â†’ commit â†’ push â†’ handoff
â”‚   â”‚       â”œâ”€â”€ handoff.ts        # buildHandoff() â€” git diff stat parsing
â”‚   â”‚       â””â”€â”€ index.ts          # Barrel export
â”‚   â”‚
â”‚   â””â”€â”€ dashboard/                # NOT STARTED â€” future web UI (React)
â”‚
â”œâ”€â”€ infra/                        # Modal infrastructure (Python)
â”‚   â”œâ”€â”€ sandbox_image.py          # Modal Image: Debian slim, Node 22, Git, ripgrep, pnpm, Pi SDK
â”‚   â”œâ”€â”€ spawn_sandbox.py          # Sandbox: create â†’ clone (authed) â†’ exec â†’ push â†’ read result â†’ terminate
â”‚   â”œâ”€â”€ deploy_glm5.py            # GLM-5 on 8x B200 via SGLang
â”‚   â”œâ”€â”€ glm5_client.py            # Endpoint URL resolution
â”‚   â”œâ”€â”€ config.yaml               # SGLang server config (EAGLE speculative decoding, memory, batching)
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ prompts/                      # All agent prompts (constraint-based)
â”‚   â”œâ”€â”€ root-planner.md           # Streaming planner: 50-100 tasks, overlap-tolerant
â”‚   â”œâ”€â”€ subplanner.md             # Recursive decomposition
â”‚   â”œâ”€â”€ worker.md                 # Worker: constraint-based, handoff-rich
â”‚   â””â”€â”€ reconciler.md             # Build healer: error grouping â†’ fix tasks
â”‚
â”œâ”€â”€ generated-repos/              # Project specs generated via bootstrap template
â”‚   â”œâ”€â”€ bootstrap.md              # Template for generating new project specs
â”‚   â”œâ”€â”€ README.md                 # Instructions for creating new projects
â”‚   â”œâ”€â”€ example/                  # Example project spec (SPEC, AGENTS, RUNBOOK, etc.)
â”‚   â””â”€â”€ minecraft-browser/        # VoxelCraft project spec (SPEC, AGENTS, RUNBOOK, etc.)
â”‚
â””â”€â”€ scripts/
    â””â”€â”€ test_sandbox.py           # E2E test script
```

---

## Current Status (2026-02-14)

### Phase 0: LLM Backend â€” âœ… LIVE

GLM-5 on Modal confirmed healthy. Token usage at 11% with 14 concurrent requests â€” massive headroom for 100 workers. EAGLE speculative decoding active: accept rate 0.78-0.87, ~3.3 tokens/step.

### Phase 1: Foundation â€” âœ… VALIDATED ON LIVE INFRA

| Step | Status | Details |
|------|--------|---------|
| 0a. GLM-5 endpoint live | âœ… DONE | Modal 8xB200, SGLang, EAGLE speculative decoding |
| 0b. GitHub repo created | âœ… DONE | `https://github.com/andrewcai8/swarm-minecraft.git` |
| 1a. Sandbox image builds | âœ… PASSED | Node 22, Git, ripgrep, pnpm, Pi SDK all verified |
| 1b. Single sandbox lifecycle | âœ… PASSED | Create, write, clone, exec, read, terminate |
| 1c. Pi agent in sandbox | âœ… PASSED | 26 tool calls, 62 seconds, correct output |
| 1d. Full orchestrator E2E | âœ… PASSED | 27 tasks, 0 failures, 108 commits/hr, 100% merge |

10 integration bugs found and fixed during validation.

### Phase 2: Orchestrator â€” âœ… COMPLETE + STREAMING UPGRADE

| Component | Status | Lines | Details |
|-----------|--------|-------|---------|
| `orchestrator.ts` | âœ… DONE | 262 | Factory: wires all components, GitMutex, GIT_TOKEN, background merge |
| `config.ts` | âœ… DONE | 110 | Multi-endpoint JSON, default maxWorkers=100 |
| `planner.ts` | âœ… DONE | 346 | **Streaming**: dispatch immediately, collect handoffs, replan on 3+ completions |
| `subplanner.ts` | âœ… DONE | 441 | Recursive decomposition, no local branch creation |
| `shared.ts` | âœ… DONE | 124 | ConcurrencyLimiter + GitMutex |
| `worker-pool.ts` | âœ… DONE | 176 | 50MB maxBuffer, GIT_TOKEN passthrough |
| `task-queue.ts` | âœ… DONE | 366 | PriorityQueue + state machine |
| `merge-queue.ts` | âœ… DONE | 244 | Background mode, fetch-from-origin, GitMutex |
| `monitor.ts` | âœ… DONE | 152 | Health polling, stuck detection, metrics |
| `llm-client.ts` | âœ… DONE | 301 | Multi-endpoint weighted routing |
| `reconciler.ts` | âœ… DONE | 235 | Timer-based build healer |
| `main.ts` | âœ… DONE | 91 | Entry point with signal handling |

**Architecture (Cursor "self-driving codebases" inspired):**
- Streaming planner loop (not batch-and-wait)
- Background merge queue (doesn't block planning)
- GitMutex serializes all local git operations
- Workers push branches to GitHub (token-authed)
- Merge queue fetches from origin before merging
- No local branch creation (branches created inside sandboxes only)
- Relaxed overlap policy (accept turbulence, system converges)
- Task fan-out: 50-100 per planning call

### Phase 2 Prompts â€” âœ… REWRITTEN (constraint-based)

| Prompt | Lines | Style |
|--------|-------|-------|
| `root-planner.md` | 131 | 50-100 tasks, NEVER < 20, overlap accepted, streaming-aware |
| `worker.md` | 67 | NEVER TODOs, NEVER modify outside scope, 3 strikes = stop |
| `reconciler.md` | 118 | NEVER > 5 fix tasks, ALWAYS cite error |
| `subplanner.md` | 154 | Unchanged |

### Phase 3: Target Project (VoxelCraft) â€” âœ… SPEC COMPLETE

Specs live in `generated-repos/minecraft-browser/` (SPEC.md, AGENTS.md, RUNBOOK.md, etc.).
GitHub: `https://github.com/andrewcai8/swarm-minecraft.git` (1 commit: initial scaffold).
Note: `target-repo/` is not checked into this repo â€” it is cloned at runtime by the orchestrator.

### Phase 4: Dashboard â€” âœ… RICH TERMINAL UI COMPLETE / âŒ WEB UI NOT STARTED

**Rich Terminal Dashboard** (`dashboard.py` â€” 748 lines, fully functional)

A fullscreen, multi-panel TUI using Python's `rich` library that refreshes at 2 Hz. Consumes NDJSON events from the orchestrator's structured logger and `Monitor` metrics snapshots.

| Panel | Shows |
|-------|-------|
| Header | Elapsed time, active agent count (N/max), commits/hr |
| Metrics | Iteration, tasks done/total (%), failed, pending, merge rate, tokens, estimated cost |
| Agent Grid | Visual heatmap â€” colored block per slot (yellow=running, green=done, red=failed, gray=idle) |
| Merge Queue | Success rate bar, merged/conflict/failed counts |
| Activity Feed | Real-time scrolling event log (task lifecycle, merge results, reconciler sweeps, errors) |
| Footer | Overall feature progress bar (completed/total) |

Three input modes:
- `python dashboard.py --demo` â€” synthetic data generator (no orchestrator needed)
- `node packages/orchestrator/dist/main.js | python dashboard.py --stdin` â€” pipe mode
- `python dashboard.py` â€” spawns orchestrator as subprocess

**Observability backend** (`packages/orchestrator/src/monitor.ts` â€” 152 lines):
- Periodic health polling with configurable interval
- Worker timeout detection with callbacks
- Token usage and merge success/failure tracking
- Emits `MetricsSnapshot` events consumed by the dashboard

**Web UI**: Not started. No React, no web framework code. Listed as future goal in README.

---

## Code Statistics

| Category | Lines | Files |
|----------|-------|-------|
| TypeScript (packages/) | 3,783 | 15 source files |
| TypeScript (.pi/extensions/) | 436 | 1 file |
| Python (infra/) | 689 | 6 files (incl. config.yaml) |
| Python (dashboard.py) | 748 | 1 file |
| Python (scripts/) | 448 | 1 file |
| Prompts (prompts/) | 470 | 4 files |
| Generated-repos specs | 716 | 15 files |
| Tests | 1,335 | 5 test files |
| **Total** | **~8,625** | **48 files** |

Tests: 85 unit tests. All passing (<100ms).

---

## What Needs To Happen (Priority Order)

### ~~Step 0: Prerequisites~~ â€” âœ… DONE
### ~~Step 1: Validate Pipeline E2E~~ â€” âœ… DONE
### ~~Step 2: Fix What Broke~~ â€” âœ… DONE (10 bugs)
### ~~Step 2b: Architecture Upgrade~~ â€” âœ… DONE (Cursor-inspired streaming)

---

### Step 3: Full-Scale Run (100 workers) â€” ğŸ”œ NEXT

Skip gradual ramp â€” GLM-5 showed 11% utilization with 14 concurrent requests.

```bash
node packages/orchestrator/dist/main.js
```

Default: `MAX_WORKERS=100`. Streaming planner generates 50-100 tasks per iteration.

**Watch for:**
- GLM-5 saturation (token usage, queue depth, gen throughput)
- Merge conflict rate (relaxed overlap = some conflicts expected)
- Task quality (is planner producing sensible tasks?)
- Sandbox creation rate (can Modal handle 100 concurrent?)
- Git push contention (100 workers pushing simultaneously)
- Local machine (100 Python subprocesses, memory, file descriptors)

**Success criteria:**
- Sustained 100 workers for 30+ minutes
- >50% task completion rate
- Merge success rate >70%
- VoxelCraft begins taking shape

---

### Step 4: Dashboard (for the demo) â€” âœ… TERMINAL UI DONE

Rich terminal dashboard is fully built (`dashboard.py`, 749 lines). See Phase 4 above for details.

**Remaining (nice-to-have):**
- Web UI (React + WebSocket) for remote monitoring â€” not started
- Log Viewer (agent conversation replay) â€” not in terminal dashboard
- VoxelCraft Preview (embedded iframe of the game being built live) â€” requires web UI

---

### Step 5: Sustained Production Run

Multi-hour run targeting 200 FEATURES.json features. VoxelCraft should be playable.

---

### Step 6: Polish for Demo

Record metrics, screenshots, video. Show VoxelCraft + commit history.

---

## Known Issues

| Issue | Severity | Details |
|-------|----------|---------|
| RunPod down | MEDIUM | Endpoint unavailable. Modal-only for now. |
| `tokensUsed: 0` in handoff | LOW | Pi SDK counter incompatible with GLM-5 streaming. |
| No auto-merge conflict resolution | MEDIUM | Conflicts skipped + logged. Could be significant at 100 workers. |
| Unbounded subtask fan-out | MEDIUM | Could fan to ~1000 LLM calls at depth-3. |
| No web dashboard | LOW | Terminal dashboard exists. Web UI is nice-to-have for remote monitoring. |
| `shared mem limit` warnings | LOW | SGLang falls back to low-smem kernel for large prefills. |

---

## Environment Variables

```env
LLM_ENDPOINTS=[{"name":"modal-b200","endpoint":"https://cameronai--glm5-inference-glm5.us-east.modal.direct","weight":100}]
LLM_MODEL=glm-5
GIT_REPO_URL=https://github.com/andrewcai8/swarm-minecraft.git
GIT_TOKEN=<github-pat-with-push-access>

# Optional
MAX_WORKERS=100
WORKER_TIMEOUT=1800
MERGE_STRATEGY=fast-forward
TARGET_REPO_PATH=./target-repo
PYTHON_PATH=python3
LLM_MAX_TOKENS=8192
LLM_TEMPERATURE=0.7
```

## Running

```bash
pnpm run build
node packages/orchestrator/dist/main.js
```
